Во всех заданиях об ошибках пользователя или системы следует сообщать в stderr, завершаясь с ненулевым кодом возврата.
Нужно уметь правильно работать со странными именами файлов (перевод строки в имени файла, например) и корректно обрабатывать исключительные ситуации (кончилось место на диске, например).

1. Качаем хорошо

Требуется разработать скрипт, умеющий скачивать из интернета файлы по URLам, поддерживая очередь на скачивание.
Usage:
    fetch4me [-w <dir>] [-r <referer>] (<url>)* // аргументы, каждый из которых является URLом, опциональный аргумент -r, в котором передаётся реферер (работает только если передано не менее одного юрла) и опциоанльный аргумент -w, в котором передается приоритетное значение для QQEDIR (см. ниже).
Good examples:
    fetch4me http://ya.ru
    fetch4me -r http://ya.ru http://google.com https://duckduckgo.com
    fetch4me -w index.pages -r http://ya.ru https://duckduckgo.com
    fetch4me
Bad examples:
    fetch4me -r http://ya.ru

Алгоритм работы:

* зачитать файл настроек ~/.fetch4merc, в котором можно настроить две переменные:
** QQEDIR -- директория для очереди;
** GETELEMFUNC -- имя программы, которую нужно запустить;

* настроить внутренние переменные QQEDIR и GETELEMFUNC:
**QQEDIR:
*** если передан аргумент -w, то QQEDIR=ему
*** иначе взять переменную из файла настроек (её там может не быть);
*** иначе использовать ~/.fetch4me

**GETELEMFUNC:
*** взять переменную из файла настроек (аналогично);
*** иначе использовать wget.

* если демон уже запущен (см. ниже) и передано 0 юрлов, то ошибка;
* если демон уже запущен, но передано >0 юрлов, то атомарно (для каждого файла по отдельности) создать в QQEDIR файлы с реферерами и юрлами;
* иначе создать в QQEDIR аналогичные файлы (далее будем называть их запросами на скачивание) и превратиться в демона (насколько это возможно в bash, достаточно перехватывать SIGHUP).

Демон делает следующее:
* переодически изучает содержимое QQEDIR на тему появления там новых запросов на скачивание;
* каждый такой запрос добавляет себе в очередь (bash-овый array);
* последовательно скачивает файлы из очереди при помощи GETELEMFUNC (считая, что оно обладает интерфейсом wget) (по одному за раз) в файлы ~/Downloads/fetched4you/<referer>/<url> (да, да, именно имя файла -- юрл целиком).
* обновляет файл "$QQEDIR"/.queue (см. ниже);
* обновляет файл "$QQEDIR"/.status (аналогично);
* обновляет файл "$QQEDIR"/.finished (аналогично).

Файлы в QQEDIR:
* /.queue: в этот файл сериализуется очередь на скачивание, если демон крешится сам или убивается killом, то после запуска fetch4me -w <соответствующий QQEDIR> или просто fetch4me он должен восстановить очередь из этого файла и продолжить работу (используя флаг -c wget'а); этот файл нужно атомарно переписывать целиком;
* /.status: в этот файл демон выписывает текущий скачиваемый файл (если у текущего файла ещё и отмечен прогресс загрузки (<<33%>>, например), то за это дают капельку дополнительных баллов) и все файлы, находящиеся в очереди, в human-readable и grepable формате (на ваш вкус); этот файл нужно атомарно переписывать целиком в случаях, если всё хорошо; в случае ошибки (кончилось место на диске, например) об этом также следует сообщать в этот файл и крешится, но запись в файл проводить неатомарную (чтобы с некоторой вероятностью это увенчалось успехом);
* /.finished: файл со строчками формата:
<UNIX-timestamp><space><referer><space><url>
в этот файл нужно аппендить строчки и никогда его целиком не переписывать.

Ограничения на решение:
* следует использовать интерпретатор /bin/bash -e и обрабатывать все ошибки явно.

Hints:
* man bash
* man wget
* date +%s

2. -- IO подсистема слишком ленива, файл вычислен не до конца --

